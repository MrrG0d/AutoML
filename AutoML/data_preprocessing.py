{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4229642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "class LabelEncoderWrapper:\n",
    "    def __init__(self):\n",
    "        self.encoder_dict = defaultdict(LabelEncoder)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        # Применение LabelEncoder к каждому объектному столбцу\n",
    "        X_transformed = X.apply(lambda x: self.encoder_dict[x.name].fit_transform(x.astype(str)))\n",
    "        return X_transformed\n",
    "\n",
    "\n",
    "class DataFramePreprocessor:\n",
    "    def __init__(self, object_columns, scaler=StandardScaler(), imputer=SimpleImputer()):\n",
    "        self.object_columns = object_columns\n",
    "        self.scaler = scaler\n",
    "        self.imputer = imputer\n",
    "\n",
    "    def process(self, data):\n",
    "        data = self.correct_text(data)\n",
    "        data = self.drop_duplicates(data)\n",
    "        data = self.apply_label_encoder(data)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.split_data(data)\n",
    "        # Заполнение отсутствующих значений\n",
    "        X_train_imputed, X_test_imputed = self.impute_missing_values(X_train, X_test, y_train)\n",
    "        \n",
    "        # Сохраняем имена столбцов\n",
    "        self.columns = X_train_imputed.columns\n",
    "        # Преобразуем numpy.ndarray обратно в DataFrame с сохранением имен столбцов\n",
    "        X_train_imputed = pd.DataFrame(X_train_imputed, columns=self.columns)\n",
    "        X_test_imputed = pd.DataFrame(X_test_imputed, columns=self.columns)\n",
    "        \n",
    "        # Масштабирование данных\n",
    "        X_train_scaled, X_test_scaled = self.scale_features(X_train_imputed, X_test_imputed)\n",
    "        # Выбор признаков\n",
    "        X_train_selected, X_test_selected = self.select_features(X_train_scaled, y_train, X_test_scaled)\n",
    "        \n",
    "        return X_train_selected, X_test_selected, y_train, y_test\n",
    "\n",
    "    @staticmethod\n",
    "    def correct_text(data):\n",
    "        return data.apply(lambda x: x.str.strip().str.lower() if x.dtype == \"object\" else x)\n",
    "    \n",
    "    # Приводим текстовые столбцы к нижнему регистру и удаляем начальные и конечные пробелы\n",
    "    @staticmethod\n",
    "    def drop_duplicates(data):\n",
    "        return data.drop_duplicates(inplace=False)\n",
    "\n",
    "    def apply_label_encoder(self, data):\n",
    "        lew = LabelEncoderWrapper()\n",
    "        data[self.object_columns] = lew.fit_transform(data[self.object_columns])\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def split_data(data):\n",
    "        return train_test_split(data.drop(['target'], axis=1), data['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Находим оптимальный метод заполнения пропущенных значений с помощью GridSearchCV\n",
    "    def impute_missing_values(self, X_train, X_test, y_train):\n",
    "        param_grid_imputer = {'strategy': ['mean', 'median', 'most_frequent', 'constant']}\n",
    "        grid_search_imputer = GridSearchCV(self.imputer, param_grid=param_grid_imputer, cv=5, scoring='r2')\n",
    "        grid_search_imputer.fit(X_train, y_train)\n",
    "        best_imputer = grid_search_imputer.best_estimator_\n",
    "        X_train_imputed = best_imputer.transform(X_train)\n",
    "        X_test_imputed = best_imputer.transform(X_test)\n",
    "        \n",
    "        # Обратно в DataFrame с сохранением имен столбцов\n",
    "        X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "        X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test.columns)\n",
    "        \n",
    "        return X_train_imputed, X_test_imputed\n",
    "\n",
    "    # Масштабирование данных\n",
    "    def scale_features(self, X_train_imputed, X_test_imputed):\n",
    "        self.scaler.fit(X_train_imputed)\n",
    "\n",
    "        X_train_scaled = pd.DataFrame(self.scaler.transform(X_train_imputed), columns=X_train_imputed.columns)\n",
    "        X_test_scaled = pd.DataFrame(self.scaler.transform(X_test_imputed), columns=X_train_imputed.columns)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled\n",
    "\n",
    "    # Выбор признаков\n",
    "    def select_features(self, X_train, y_train, X_test):\n",
    "        # выбираем k наиболее значимых признаков\n",
    "        selector = SelectKBest(f_regression, k=X_train.shape[1])\n",
    "        selector.fit(X_train, y_train)\n",
    "        k_best = selector.k\n",
    "\n",
    "        # определяем пороговое значение для отбора признаков с помощью метода VarianceThreshold\n",
    "        selector = VarianceThreshold()\n",
    "        selector.fit(X_train)\n",
    "        threshold = np.percentile(selector.variances_, 100 - (100 / X_train.shape[1]) * k_best)\n",
    "    \n",
    "        # удаляем признаки с низкой дисперсией\n",
    "        sel = VarianceThreshold(threshold=threshold)\n",
    "        X_train = sel.fit_transform(X_train)\n",
    "        X_test = sel.transform(X_test)\n",
    "    \n",
    "        # удаляем признаки с высокой корреляцией для предотвращения мультиколлинеарности\n",
    "        corr_matrix = pd.DataFrame(X_train).corr().abs() # получаем матрицу корреляции\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # выбираем верхний треугольник матрицы корреляции\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)] # находим индексы столбцов с корреляцией больше порога\n",
    "        X_train = np.delete(X_train, to_drop, axis=1) # удаляем коррелирующие признаки\n",
    "        X_test = np.delete(X_test, to_drop, axis=1)\n",
    "\n",
    "        # отбор признаков с помощью метода RFE\n",
    "        lr = LinearRegression()\n",
    "\n",
    "        # определяем объект с кросс-валидацией\n",
    "        rfecv = RFECV(estimator=lr, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "        rfecv.fit(X_train, y_train)\n",
    "\n",
    "        # выполняем отбор признаков\n",
    "        X_train_rfecv = rfecv.transform(X_train)\n",
    "        X_test_rfecv = rfecv.transform(X_test)\n",
    "        \n",
    "        return X_train_rfecv, X_test_rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "744f57d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
